/**
 * ëŒ€ë³¸ ìƒì„± ê´€ë¦¬ë¥¼ ìœ„í•œ ì»¤ìŠ¤í…€ í›…
 */

import { useState, useEffect, useCallback } from "react";
import { useApi } from "./useApi";
import { AI_ENGINE_OPTIONS } from "../constants/scriptSettings";

export function useScriptGeneration() {
  const api = useApi();

  const [doc, setDoc] = useState(null);
  const [isLoading, setIsLoading] = useState(false);
  const [error, setError] = useState("");

  useEffect(() => {
    setDoc(null);
    setIsLoading(false);
    setError("");
  }, []);

  const getSelectedPromptContent = useCallback(
    async (promptName) => {
      try {
        const res = await api.invoke("prompts:getPairByName", promptName);
        if ((res?.ok || res?.success) && res.data) {
          return {
            script: res.data.script?.content || "",
            reference: res.data.reference?.content || "",
          };
        }
      } catch (error) {
        console.error("í”„ë¡¬í”„íŠ¸ ë‚´ìš© ë¡œë”© ì‹¤íŒ¨:", error);
      }
      return { script: "", reference: "" };
    },
    [api]
  );

  const runGenerate = useCallback(
    async (form, toast = null) => {
      setError("");
      setIsLoading(true);

      try {
        // ì „ì—­ ì„¤ì •ì—ì„œ LLM ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°
        let globalLlmModel = null;
        try {
          const llmModelResult = await api.invoke("settings:get", "llmModel");
          globalLlmModel = llmModelResult?.data || llmModelResult;
        } catch (error) {
          console.warn("ì „ì—­ ì„¤ì • LLM ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨:", error);
        }

        // ì „ì—­ ì„¤ì • ìš°ì„ , ì—†ìœ¼ë©´ form.aiEngine ì‚¬ìš©
        const finalEngine = globalLlmModel || form.aiEngine || "anthropic";
        console.log("ğŸ¯ AI ìƒì„± ì—”ì§„:", finalEngine);

        let promptContent = { script: "", reference: "" };
        if (form.promptName) {
          promptContent = await getSelectedPromptContent(form.promptName);
        }

        const selectedEngine = AI_ENGINE_OPTIONS.find((engine) => engine.key === finalEngine);

        const payload = {
          llm: finalEngine,
          type: "auto",
          topic: form.topic,
          style: form.style,
          duration: form.durationMin,
          maxScenes: form.maxScenes,
          temperature: form.temperature,
          prompt: promptContent.script || form.customPrompt,
          referenceText: form.referenceScript,
          cpmMin: form.cpmMin || 300,
          cpmMax: form.cpmMax || 400,
        };

        const getTimeoutForDuration = (minutes) => {
          if (minutes >= 90) return 600000;
          if (minutes >= 60) return 480000;
          if (minutes >= 30) return 300000;
          if (minutes >= 20) return 180000;
          return 120000;
        };

        const timeoutMs = getTimeoutForDuration(form.durationMin);
        const res = await api.invoke("llm/generateScript", payload, { timeout: timeoutMs });

        if (res && res.data && res.data.scenes) {
          const actualScenes = res.data.scenes.length;
          const totalChars = res.data.scenes.reduce((sum, scene) => sum + (scene.text || "").length, 0);

          setDoc(res.data);
          console.log(`âœ… ëŒ€ë³¸ ìƒì„± ì™„ë£Œ: ${actualScenes}ê°œ ì¥ë©´ (${totalChars}ì)`);

          return res.data;
        } else {
          throw new Error("API ì‘ë‹µì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.");
        }
      } catch (e) {
        const errorMessage = e?.message || "ëŒ€ë³¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.";
        setError(errorMessage);
        // ì˜¤ë¥˜ ë©”ì‹œì§€ëŠ” error ìƒíƒœë¡œ ì „ë‹¬
        console.error("ëŒ€ë³¸ ìƒì„± ì˜¤ë¥˜:", e);
      } finally {
        setIsLoading(false);
      }
    },
    [api, getSelectedPromptContent]
  );

  return {
    doc,
    setDoc,
    isLoading,
    setIsLoading,
    error,
    setError,
    runGenerate,
    getSelectedPromptContent,
    AI_ENGINE_OPTIONS,
  };
}
