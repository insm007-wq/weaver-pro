/**
 * ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ìœ í‹¸ë¦¬í‹°
 *
 * @description
 * AIë¥¼ í†µí•´ ëŒ€ë³¸ì„ ìƒì„±í•˜ëŠ” ìœ í‹¸ë¦¬í‹°
 * ë‹¤ì–‘í•œ LLM ëª¨ë¸ê³¼ í”„ë¡¬í”„íŠ¸ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.
 *
 * @features
 * - ğŸ¤– ë‹¤ì¤‘ LLM ëª¨ë¸ ì§€ì› (Anthropic, OpenAI)
 * - ğŸ“ í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ëŒ€ë³¸ ìƒì„±
 * - âš™ï¸ ì„¸ë¶€ ì„¤ì • ì˜µì…˜ ì§€ì›
 * - ğŸ¯ ì‘ë‹µ ê²€ì¦ ë° ì˜¤ë¥˜ ì²˜ë¦¬
 *
 * @author Weaver Pro Team
 * @version 1.0.0
 */

/**
 * AIë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€ë³¸ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
 *
 * @param {Object} form - í¼ ì„¤ì • ë°ì´í„°
 * @param {Object} globalSettings - ì „ì—­ ì„¤ì •
 * @param {Function} getSelectedPromptContent - í”„ë¡¬í”„íŠ¸ ë‚´ìš© ê°€ì ¸ì˜¤ê¸° í•¨ìˆ˜
 * @param {Function} api - API í˜¸ì¶œ í•¨ìˆ˜
 * @param {Function} setDoc - ë¬¸ì„œ ì„¤ì • í•¨ìˆ˜
 * @param {Function} setFullVideoState - ìƒíƒœ ì—…ë°ì´íŠ¸ í•¨ìˆ˜
 * @param {Object} toast - í† ìŠ¤íŠ¸ ì•Œë¦¼ ê°ì²´
 * @param {Function} addLog - ë¡œê·¸ ì¶”ê°€ í•¨ìˆ˜
 * @returns {Promise<Object>} ìƒì„±ëœ ìŠ¤í¬ë¦½íŠ¸ ë°ì´í„°
 */
export async function generateScriptStep(form, globalSettings, getSelectedPromptContent, api, setDoc, setFullVideoState, toast, addLog) {
  try {
    let promptContent = { script: "", reference: "" };
    if (form.promptName) {
      promptContent = await getSelectedPromptContent(form.promptName);
    }

    // ìœ íš¨í•œ LLM ëª¨ë¸ì¸ì§€ í™•ì¸ í›„ ì„¤ì •
    const validLlmModels = ["anthropic", "openai-gpt5mini"];
    const selectedLlm = globalSettings.llmModel && validLlmModels.includes(globalSettings.llmModel)
      ? globalSettings.llmModel
      : "anthropic"; // ê¸°ë³¸ê°’

    // âœ… í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œ ë¶„ì„ (í˜ì´ë¡œë“œ êµ¬ì„± ì „ì— ë¨¼ì € ì„ ì–¸)
    const hasReference = !!(form.referenceScript && form.referenceScript.trim());
    const hasTopic = !!(form.topic && form.topic.trim());

    // âœ… í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œì— ë”°ë¥¸ í˜ì´ë¡œë“œ êµ¬ì„±
    const isReferenceImproveMode = hasReference && !hasTopic;

    // ë ˆí¼ëŸ°ìŠ¤ ê°œì„  ëª¨ë“œìš© ì „ìš© í”„ë¡¬í”„íŠ¸
    const referenceImprovePrompt = `ë‹¤ìŒ ë ˆí¼ëŸ°ìŠ¤ ëŒ€ë³¸ì„ ë¶„ì„í•˜ì—¬ êµ¬ì¡°ì™€ ìŠ¤íƒ€ì¼ì„ ê°œì„ í•œ ë” ë‚˜ì€ ë²„ì „ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:

## ğŸ“‹ ë ˆí¼ëŸ°ìŠ¤ ëŒ€ë³¸:
{referenceText}

## ğŸ¯ ê°œì„  ëª©í‘œ:
- ì›ë³¸ì˜ í•µì‹¬ ë©”ì‹œì§€ì™€ í†¤ì•¤ë§¤ë„ˆ ìœ ì§€
- êµ¬ì¡°ì  ì™„ì„±ë„ì™€ ë…¼ë¦¬ì  íë¦„ ê°œì„ 
- ì‹œì²­ì ëª°ì…ë„ë¥¼ ë†’ì´ëŠ” í‘œí˜„ ê°•í™”
- ë” ëª…í™•í•˜ê³  ì„íŒ©íŠ¸ ìˆëŠ” ì „ë‹¬ë ¥
- ì ì ˆí•œ í˜¸í¡ê³¼ ë¦¬ë“¬ê° ì¡°ì •

## ğŸ“ ê°œì„  ê°€ì´ë“œ:

**ìŠ¤íƒ€ì¼: {style}**
**ëª©í‘œ ê¸¸ì´: {duration}ë¶„**
**ìµœëŒ€ ì¥ë©´ ìˆ˜: {maxScenes}ê°œ**

**ì‹¤ì œ ìŒì„± ì‹œê°„ ê¸°ì¤€:**
- í•œêµ­ì–´ ìŒì„± ì†ë„: ë¶„ë‹¹ 300-400ì
- ì´ {duration}ë¶„ = ì´ {minCharacters}-{maxCharacters}ì í•„ìš”
- ê° ì¥ë©´ í‰ê·  {avgCharactersPerScene}ì ì´ìƒ í•„ìˆ˜

**ê°œì„  í¬ì¸íŠ¸:**
1. **ë„ì…ë¶€ ê°•í™”**: ë” í¥ë¯¸ë¡œìš´ ì‹œì‘ìœ¼ë¡œ ì‹œì²­ì ì–´í…ì…˜ í™•ë³´
2. **ë‚´ìš© í™•ì¥**: í•µì‹¬ í¬ì¸íŠ¸ë¥¼ ë” êµ¬ì²´ì ì´ê³  ìƒì„¸í•˜ê²Œ ì„¤ëª…
3. **ì˜ˆì‹œ ë³´ê°•**: ì‹¤ì œ ì‚¬ë¡€ì™€ êµ¬ì²´ì  ì˜ˆì‹œ ì¶”ê°€
4. **ë…¼ë¦¬ì  êµ¬ì¡°**: ë” ëª…í™•í•œ ë‹¨ê³„ì  ì „ê°œ
5. **ë§ˆë¬´ë¦¬ ê°œì„ **: ì„íŒ©íŠ¸ ìˆëŠ” ê²°ë¡ ê³¼ ì•¡ì…˜ ìœ ë„

**ğŸ”¥ ì¤‘ìš”**: ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.

ì‘ë‹µ í˜•ì‹:
{
  "title": "ê°œì„ ëœ ì˜ìƒ ì œëª© (ë” ì„íŒ©íŠ¸ ìˆê³  êµ¬ì²´ì ìœ¼ë¡œ)",
  "total_duration": {duration},
  "total_characters": "ì‹¤ì œ ì´ ê¸€ì ìˆ˜",
  "scenes": [
    {
      "scene_number": 1,
      "text": "ê°œì„ ëœ ì¥ë©´ í…ìŠ¤íŠ¸ (ì›ë³¸ë³´ë‹¤ ë” ì™„ì„±ë„ ë†’ê²Œ)",
      "duration": 45,
      "character_count": "ì´ ì¥ë©´ì˜ ì‹¤ì œ ê¸€ì ìˆ˜",
      "visual_description": "ê°œì„ ëœ ì‹œê°ì  ìš”ì†Œ ì„¤ëª…"
    }
  ]
}`;

    const payload = {
      llm: selectedLlm,
      type: isReferenceImproveMode ? "reference_improve" : "auto",
      topic: hasTopic ? form.topic : (hasReference ? "ë ˆí¼ëŸ°ìŠ¤ ëŒ€ë³¸ ê°œì„ " : form.topic),
      style: form.style,
      duration: form.durationMin,
      maxScenes: form.maxScenes,
      temperature: form.temperature,
      prompt: isReferenceImproveMode ? referenceImprovePrompt : (promptContent.script || form.customPrompt),
      referenceText: form.referenceScript,
      cpmMin: 300,
      cpmMax: 400,
    };

    console.log("ğŸ” globalSettings:", globalSettings);
    console.log("ğŸ” LLM Model:", globalSettings.llmModel);

    const referenceAnalysis = {
      hasReference,
      hasTopic,
      referenceLength: form.referenceScript ? form.referenceScript.trim().length : 0,
      previewText: form.referenceScript ? form.referenceScript.substring(0, 100) + "..." : "ì—†ìŒ",
      wordCount: form.referenceScript ? form.referenceScript.trim().split(/\s+/).length : 0,
      isOptimal: form.referenceScript ? form.referenceScript.trim().length >= 500 : false,
      processingMode: hasReference ? (hasTopic ? "reference_guided" : "reference_improve") : "topic_only"
    };

    console.log("ğŸ“œ ë ˆí¼ëŸ°ìŠ¤ ëŒ€ë³¸ ë¶„ì„:", referenceAnalysis);
    console.log("ğŸ¯ ìƒì„± ëª¨ë“œ:",
      referenceAnalysis.processingMode === "reference_guided" ? "ë ˆí¼ëŸ°ìŠ¤ ê°€ì´ë“œ ëª¨ë“œ (í†¤&ë§¤ë„ˆ ë¶„ì„)" :
      referenceAnalysis.processingMode === "reference_improve" ? "ë ˆí¼ëŸ°ìŠ¤ ê°œì„  ëª¨ë“œ (ë” ë‚˜ì€ ë²„ì „ ìƒì„±)" :
      "ì¼ë°˜ í† í”½ ëª¨ë“œ (ê¸°ë³¸ ì„¤ì •ë§Œ)"
    );
    console.log("ì „ì†¡í•  payload:", payload);

    // âœ… í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œ ë¡œê¹…
    if (addLog) {
      addLog("ğŸ“ ëŒ€ë³¸ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤...");

      // ëª¨ë“œë³„ ì•ˆë‚´
      if (referenceAnalysis.processingMode === "reference_improve") {
        addLog(`ğŸ”„ ë ˆí¼ëŸ°ìŠ¤ ê°œì„  ëª¨ë“œ: ê¸°ì¡´ ëŒ€ë³¸ì„ ë¶„ì„í•´ ë” ë‚˜ì€ ë²„ì „ì„ ìƒì„±í•©ë‹ˆë‹¤`);
        addLog(`ğŸ“‹ ì›ë³¸ ëŒ€ë³¸: ë ˆí¼ëŸ°ìŠ¤ë¡œ ì œê³µë¨`);
      } else if (referenceAnalysis.processingMode === "reference_guided") {
        addLog(`ğŸ­ ë ˆí¼ëŸ°ìŠ¤ ê°€ì´ë“œ ëª¨ë“œ: ë ˆí¼ëŸ°ìŠ¤ ìŠ¤íƒ€ì¼ë¡œ ìƒˆ ì£¼ì œì˜ ëŒ€ë³¸ì„ ìƒì„±í•©ë‹ˆë‹¤`);
        addLog(`ğŸ“‹ ì£¼ì œ: ${form.topic}`);
      } else {
        addLog(`ğŸ“‹ ì£¼ì œ: ${form.topic}`);
      }

      addLog(`ğŸ¨ ìŠ¤íƒ€ì¼: ${form.style}`);
      addLog(`â±ï¸ ê¸¸ì´: ${form.durationMin}ë¶„`);
      addLog(`ğŸ¤– AI ëª¨ë¸: ${selectedLlm === "anthropic" ? "Anthropic Claude" : "OpenAI GPT-5 Mini"}`);

      // âœ… í–¥ìƒëœ ë ˆí¼ëŸ°ìŠ¤ ëŒ€ë³¸ ì¶”ì  ë¡œê¹…
      if (hasReference) {
        const refLength = form.referenceScript.trim().length;
        const wordCount = form.referenceScript.trim().split(/\s+/).length;
        const isOptimal = refLength >= 500;

        addLog(`ğŸ“œ ë ˆí¼ëŸ°ìŠ¤ ëŒ€ë³¸: ì ìš©ë¨ (${refLength.toLocaleString()}ì, ${wordCount.toLocaleString()}ë‹¨ì–´)`);

        if (referenceAnalysis.processingMode === "reference_improve") {
          addLog(`ğŸ“ˆ ì´ ë ˆí¼ëŸ°ìŠ¤ë¥¼ ë¶„ì„í•´ êµ¬ì¡°ì™€ ìŠ¤íƒ€ì¼ì„ ê°œì„ í•œ ìƒˆë¡œìš´ ë²„ì „ì„ ìƒì„±í•©ë‹ˆë‹¤`);
        } else {
          addLog(`ğŸ­ ë ˆí¼ëŸ°ìŠ¤ì˜ í†¤ì•¤ë§¤ë„ˆë¥¼ ë¶„ì„í•˜ì—¬ ìƒˆë¡œìš´ ì£¼ì œì— ì ìš©í•©ë‹ˆë‹¤`);
        }

        addLog(`ğŸ“Š ë ˆí¼ëŸ°ìŠ¤ í’ˆì§ˆ: ${isOptimal ? "âœ… ìµœì " : "âš ï¸ ë¶€ì¡±"} (ê¶Œì¥: 500ì ì´ìƒ)`);

        // í˜‘ë ¥ì—…ì²´ ìˆ˜ì¤€ ìƒì„¸ ë¶„ì„ ë¡œê¹…
        if (wordCount > 0) {
          const avgWordLength = refLength / wordCount;
          addLog(`ğŸ” ë¶„ì„ ê²°ê³¼: í‰ê·  ë‹¨ì–´ ê¸¸ì´ ${avgWordLength.toFixed(1)}ì`);
        }

        // ë ˆí¼ëŸ°ìŠ¤ ë¯¸ë¦¬ë³´ê¸° ë¡œê¹… (ì²˜ìŒ 50ì)
        const preview = form.referenceScript.trim().substring(0, 50);
        addLog(`ğŸ‘ï¸ ë ˆí¼ëŸ°ìŠ¤ ë¯¸ë¦¬ë³´ê¸°: "${preview}${refLength > 50 ? "..." : ""}"`);
      } else {
        addLog(`ğŸ“œ ë ˆí¼ëŸ°ìŠ¤ ëŒ€ë³¸: ì‚¬ìš© ì•ˆí•¨ (ê¸°ë³¸ ì„¤ì •ë§Œ ì‚¬ìš©)`);
        addLog(`ğŸ’¡ í˜‘ë ¥ì—…ì²´ì²˜ëŸ¼ ë ˆí¼ëŸ°ìŠ¤ë¥¼ í™œìš©í•˜ë ¤ë©´ 500ì ì´ìƒ ì…ë ¥í•˜ì„¸ìš”`);
      }

      // ì˜ˆìƒ ì‹œê°„ ê³„ì‚° (ì¥ë©´ ìˆ˜ì— ë”°ë¼)
      const estimatedSeconds = Math.max(30, form.maxScenes * 5);
      addLog(`â³ ì˜ˆìƒ ì†Œìš” ì‹œê°„: ì•½ ${estimatedSeconds}ì´ˆ`);
    }

    await new Promise((resolve) => setTimeout(resolve, 3000));

    let res;
    try {
      res = await api.invoke("llm/generateScript", payload, { timeout: 120000 });
    } catch (error) {
      // LLM ëª¨ë¸ ì˜¤ë¥˜ ì‹œ ìë™ ì „í™˜ ì²˜ë¦¬
      if (selectedLlm === "openai-gpt5mini" && (
        error.message.includes("invalid_request") ||
        error.message.includes("model_not_found") ||
        error.message.includes("not available")
      )) {
        if (addLog) {
          addLog(`âš ï¸ OpenAI GPT-5 Mini ì‘ë‹µì´ ìœ íš¨í•˜ì§€ ì•Šì•„ Anthropic Claudeë¡œ ìë™ ì „í™˜`, "warning");
          addLog(`ğŸ”„ ë” ì•ˆì •ì ì¸ Claude ëª¨ë¸ë¡œ ë‹¤ì‹œ ì‹œë„í•©ë‹ˆë‹¤.`, "info");
        }

        toast.warning("OpenAI GPT-5 Mini â†’ Anthropic Claude ìë™ ì „í™˜: ëª¨ë¸ ì˜¤ë¥˜");

        // Anthropic Claudeë¡œ ì¬ì‹œë„
        const fallbackPayload = { ...payload, llm: "anthropic" };
        res = await api.invoke("llm/generateScript", fallbackPayload, { timeout: 120000 });

        if (addLog && res && res.data && res.data.scenes) {
          addLog(`âœ… Claude ëª¨ë¸ë¡œ ìë™ ì „í™˜ ì™„ë£Œ!`, "success");
        }
      } else {
        throw error; // ë‹¤ë¥¸ ì—ëŸ¬ëŠ” ê·¸ëŒ€ë¡œ ë˜ì§€ê¸°
      }
    }

    console.log("ğŸ” API ì‘ë‹µ í™•ì¸:", res);

    if (res && res.data && res.data.scenes && Array.isArray(res.data.scenes) && res.data.scenes.length > 0) {
      // âœ… í–¥ìƒëœ ì„±ê³µ ë¡œê·¸ (í˜‘ë ¥ì—…ì²´ ìˆ˜ì¤€)
      if (addLog) {
        addLog(`âœ… ëŒ€ë³¸ ìƒì„± ì™„ë£Œ! ${res.data.scenes.length}ê°œì˜ ì¥ë©´ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.`);
        addLog(`ğŸ“– ì œëª©: "${res.data.title || 'ìƒì„±ëœ ëŒ€ë³¸'}"`);

        // ì´ ì˜ˆìƒ ì¬ìƒ ì‹œê°„ ê³„ì‚°
        const totalDuration = res.data.scenes.reduce((sum, scene) => sum + (scene.duration || 0), 0);
        if (totalDuration > 0) {
          addLog(`â±ï¸ ì´ ì˜ˆìƒ ì¬ìƒ ì‹œê°„: ${Math.round(totalDuration)}ì´ˆ`);
        }

        // âœ… í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œë³„ ì„±ê³µ ì¶”ì 
        if (hasReference) {
          const generatedLength = res.data.scenes.reduce((sum, scene) => sum + (scene.narration || "").length, 0);
          const referenceLength = form.referenceScript.trim().length;
          const lengthRatio = generatedLength / referenceLength;

          if (referenceAnalysis.processingMode === "reference_improve") {
            addLog(`ğŸ“ˆ ë ˆí¼ëŸ°ìŠ¤ ê°œì„  ì™„ë£Œ: ì›ë³¸ì„ ë¶„ì„í•´ ë” ë‚˜ì€ ë²„ì „ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤`);
            addLog(`ğŸ“ ê¸¸ì´ ë³€í™”: ì›ë³¸ ${referenceLength}ì â†’ ê°œì„ ë¨ ${generatedLength}ì (${lengthRatio.toFixed(1)}ë°°)`);
            addLog(`âœ¨ êµ¬ì¡°ì™€ ìŠ¤íƒ€ì¼ì´ ê°œì„ ëœ ìƒˆë¡œìš´ ëŒ€ë³¸ì´ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤`);
          } else {
            addLog(`ğŸ¯ ë ˆí¼ëŸ°ìŠ¤ ê°€ì´ë“œ ì™„ë£Œ: ì›ë³¸ í†¤ì•¤ë§¤ë„ˆê°€ ìƒˆë¡œìš´ ì£¼ì œì— ì„±ê³µì ìœ¼ë¡œ ì ìš©ë¨`);
            addLog(`ğŸ“ ê¸¸ì´ ë¹„êµ: ë ˆí¼ëŸ°ìŠ¤ ${referenceLength}ì â†’ ìƒì„±ë¨ ${generatedLength}ì (${lengthRatio.toFixed(1)}ë°°)`);
            addLog(`ğŸ”„ ìŠ¤íƒ€ì¼ ì „ì´: "${form.topic}"ì— ë ˆí¼ëŸ°ìŠ¤ ìŠ¤íƒ€ì¼ ì ìš©ì™„ë£Œ`);
          }
        } else {
          addLog(`ğŸ¨ ì¼ë°˜ ìƒì„±: ì„¤ì •ëœ ìŠ¤íƒ€ì¼(${form.style})ê³¼ ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ìƒì„±ë¨`);
        }
      }

      setDoc(res.data);
      setFullVideoState(prev => ({
        ...prev,
        results: { ...prev.results, script: res.data },
        progress: { ...prev.progress, script: 100 },
        streamingScript: "",
      }));
      return res.data;
    } else {
      console.error("âŒ ëŒ€ë³¸ ìƒì„± ì‹¤íŒ¨ ìƒì„¸:");
      console.error("- resê°€ ì¡´ì¬í•˜ëŠ”ê°€?", !!res);
      console.error("- res.scenesê°€ ì¡´ì¬í•˜ëŠ”ê°€?", !!res?.scenes);
      console.error("- scenesê°€ ë°°ì—´ì¸ê°€?", Array.isArray(res?.scenes));
      console.error("- scenes ê¸¸ì´:", res?.scenes?.length);
      console.error("- ì „ì²´ ì‘ë‹µ êµ¬ì¡°:", JSON.stringify(res, null, 2));

      const errorMsg = `ëŒ€ë³¸ ìƒì„± API ì‘ë‹µì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.`;
      if (addLog) {
        addLog(`âŒ ${errorMsg}`, "error");
      }
      throw new Error(errorMsg);
    }
  } catch (error) {
    // ì—ëŸ¬ ë¡œê·¸
    if (addLog) {
      addLog(`âŒ ëŒ€ë³¸ ìƒì„± ì‹¤íŒ¨: ${error.message}`, "error");
    }
    throw error;
  }
}

/**
 * ëŒ€ë³¸ ìƒì„±ì„ ìœ„í•œ í˜ì´ë¡œë“œë¥¼ ì¤€ë¹„í•˜ëŠ” í•¨ìˆ˜
 *
 * @param {Object} form - í¼ ë°ì´í„°
 * @param {Object} globalSettings - ì „ì—­ ì„¤ì •
 * @param {Object} promptContent - í”„ë¡¬í”„íŠ¸ ë‚´ìš©
 * @returns {Object} API í˜¸ì¶œì„ ìœ„í•œ í˜ì´ë¡œë“œ
 */
export function prepareScriptPayload(form, globalSettings, promptContent) {
  const validLlmModels = ["anthropic", "openai-gpt5mini"];
  const selectedLlm = globalSettings.llmModel && validLlmModels.includes(globalSettings.llmModel)
    ? globalSettings.llmModel
    : "anthropic";

  return {
    llm: selectedLlm,
    type: "auto",
    topic: form.topic,
    style: form.style,
    duration: form.durationMin,
    maxScenes: form.maxScenes,
    temperature: form.temperature,
    prompt: promptContent.script || form.customPrompt,
    referenceText: form.referenceScript,
    cpmMin: 300,
    cpmMax: 400,
  };
}

/**
 * ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì‘ë‹µì„ ê²€ì¦í•˜ëŠ” í•¨ìˆ˜
 *
 * @param {Object} response - API ì‘ë‹µ
 * @returns {boolean} ìœ íš¨ì„± ì—¬ë¶€
 */
export function validateScriptResponse(response) {
  return response &&
         response.data &&
         response.data.scenes &&
         Array.isArray(response.data.scenes) &&
         response.data.scenes.length > 0;
}

/**
 * LLM ëª¨ë¸ ìœ íš¨ì„±ì„ í™•ì¸í•˜ê³  ê¸°ë³¸ê°’ì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
 *
 * @param {string} requestedModel - ìš”ì²­ëœ ëª¨ë¸
 * @returns {string} ìœ íš¨í•œ ëª¨ë¸ëª…
 */
export function validateLlmModel(requestedModel) {
  const validLlmModels = ["anthropic", "openai-gpt5mini"];
  return validLlmModels.includes(requestedModel) ? requestedModel : "anthropic";
}

